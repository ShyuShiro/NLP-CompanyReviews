{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f5c20dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99876bfc",
   "metadata": {},
   "source": [
    "Lets get data request from the webpage and display the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "0220e68f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html><html lang=\"en-US\"><head><meta charSet=\"UTF-8\"/><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/><link rel=\"shortcut icon\" type=\"image/x-icon\" href=\"https://cdn.trustpilot.net/brand-assets/4.3.0/favicons/favicon.ico\"/><link rel=\"manifest\" href=\"/manifest.json\"/><meta name=\"application-name\" content=\"Trustpilot\"/><meta name=\"theme-color\" content=\"#1c1c1c\"/><link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"https://cdn.trustpilot.net/brand-assets/4.3.0/favicons/a'"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(\"https://www.trustpilot.com/review/www.corsair.com?page=10\")\n",
    "r.text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e5508",
   "metadata": {},
   "source": [
    "Text is a giant HTML soup and we're only interested in the reviews on the page\n",
    "- Need to find the div + class structure for reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "1c9d9594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "reviews = soup.find_all(\"div\", {\"class\": \"styles_reviewCardInner__EwDq2\"})\n",
    "stars = soup.find_all(\"div\",\"star-rating_starRating__4rrcf star-rating_medium__iN6Ty\")\n",
    "print(len(reviews))\n",
    "print(len(stars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374ce7b",
   "metadata": {},
   "source": [
    "There's 4 more stars than reviews .. why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "c19f96e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"TrustScore 2 out of 5\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-2.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 3 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-3.svg\"/>\n",
      "<img alt=\"Rated 4 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-4.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 3 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-3.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 3 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-3.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 4 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-4.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 5 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-5.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 5 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-5.svg\"/>\n",
      "<img alt=\"\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-4.svg\"/>\n",
      "<img alt=\"\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.5.svg\"/>\n",
      "<img alt=\"\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.5.svg\"/>\n"
     ]
    }
   ],
   "source": [
    "for star in stars:\n",
    "    print(star.find_all(\"img\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61921609",
   "metadata": {},
   "source": [
    "The first entry is the company's overall score while the last 3 entries are scores of other companies in the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "213c7992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 3 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-3.svg\"/>\n",
      "<img alt=\"Rated 4 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-4.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 3 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-3.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 3 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-3.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 4 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-4.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 5 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-5.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 1 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-1.svg\"/>\n",
      "<img alt=\"Rated 5 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-5.svg\"/>\n"
     ]
    }
   ],
   "source": [
    "stars = stars[1:-3] #Fixed\n",
    "for star in stars:\n",
    "    print(star.find_all(\"img\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a21be6",
   "metadata": {},
   "source": [
    "Above I've used Chrome's Object Painter to discover the div container and its class name for reviews ... here's an example of how to get the review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "b0b78e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"star-rating_starRating__4rrcf star-rating_medium__iN6Ty\"><img alt=\"Rated 3 out of 5 stars\" src=\"https://cdn.trustpilot.net/brand-assets/4.1.0/stars/stars-3.svg\"/></div>\n",
      "\n",
      "Rating is: 3\n"
     ]
    }
   ],
   "source": [
    "#Show a random review\n",
    "import numpy as np\n",
    "rand = np.random.choice(len(reviews))\n",
    "\n",
    "#How to get the star rating\n",
    "print(stars[rand])\n",
    "print(\"\\nRating is: \"+stars[rand].find_all(\"img\")[0]['src'][-5]) #Find the img, access the first image (only image), go to src tag, grab the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "e2a53f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HWHandsome White Man1 reviewUSMay 24, 2022How are you this useless?Date of experience: May 24, 2022\n"
     ]
    }
   ],
   "source": [
    "#Show a random review\n",
    "import numpy as np\n",
    "rand = np.random.choice(len(reviews))\n",
    "print(reviews[rand].get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63085c07",
   "metadata": {},
   "source": [
    "Need to create a function to gather the following from the review:\n",
    "- The date of the review (For timeline chart purposes)\n",
    "- Body of the review (Text not including the name or location)\n",
    "> Subsequently use NLP filter the text for a word cloud graphic\n",
    "- Location of the Reviewer (Ex: US vs AT vs GB)\n",
    "> Subsequently need to discipher these 2 letter codes because \"AT\" is Austria and \"GB\" is Great Britain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "a5c8cd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "July 01, 2022\n",
      "January 16, 2022\n",
      "November 21, 2022\n",
      "March 13, 2023\n",
      "May 17, 2023\n",
      "July 01, 2022\n",
      "May 08, 2023\n",
      "August 08, 2023\n",
      "April 01, 2022\n",
      "August 24, 2022\n",
      "July 24, 2023\n",
      "September 28, 2022\n",
      "April 05, 2022\n",
      "February 17, 2022\n",
      "January 02, 2024\n",
      "September 18, 2023\n",
      "January 04, 2024\n",
      "April 18, 2023\n",
      "May 24, 2022\n",
      "January 09, 2023\n"
     ]
    }
   ],
   "source": [
    "def find_date(txt):\n",
    "    '''\n",
    "    Function to find the date -- Use Date of Experience\n",
    "    '''\n",
    "    try:\n",
    "        sub_str = txt.find_all(\"p\")[1].get_text() #\"Date of experience: January 02, 2024\"\n",
    "        start = re.search(\"Date of experience:\",sub_str).span()[1]\n",
    "        return sub_str[start+1:]\n",
    "    except:\n",
    "        start = re.search(\"Date of experience: \",txt.get_text()).span()[1]\n",
    "        try: #In the event there's a Company reply\n",
    "            end = re.search(\"Reply\",txt.get_text()).span()[0]\n",
    "            return txt.get_text()[start:end] #Only get the date\n",
    "        except:\n",
    "            return txt.get_text()[start:] #Else this is the end of the string already\n",
    "\n",
    "for i in reviews: #Test\n",
    "    print(find_date(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2118488b",
   "metadata": {},
   "source": [
    "This kind of convenient -- Replies from Corsair would appear after the \"Date of experience\" text. Lets update the `find_date`function and then figure out how to extract replies from the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "40f8eaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Reply\n",
      "No Reply\n",
      "No Reply\n",
      "Nicky,We believe you should have the product in hand after yesterday's delivery. Please reply to the ticket and let us know if all is well.We certainly apologize for the delay you experienced with this issue.\n",
      "No Reply\n",
      "Hello, we apologize for the delay in completing your warranty exchange. Our team will reach out to you on your existing support ticket with an update.\n",
      "No Reply\n",
      "Hi David,Combining two separate RAM kits, even if they are of the same model, can lead to compatibility issues due to manufacturing variations in timing, voltage, memory ICs, and configuration. These differences may cause instability, crashes, or boot failures. I apologize for any inconvenience that this may have caused. For future reference, more information regarding mixing memory kits can be found in our help center - https://help.corsair.com/hc/en-usThank you for your feedback!\n",
      "Please contact our support team at help.corsair.com, or if you already have an existing support ticket starting with \"200\" let us know the number so we can investigate.\n",
      "Hello Cooper. If your products are still within warranty coverage please contact our team at help.corsair.com for assistance with your claim.\n",
      "Hello, We're regret to hear about your experience with our iCUE software. We apologize for any inconvenience it may have caused you. Our team is here to help address any issues you're facing and provide assistance to improve your overall experience. Please feel free to share more details about your concerns, and we'll do our best to assist you in resolving them. Thank you for your feedback!\n",
      "No Reply\n",
      "Thank you for your review. Corsair offers a 30 day money back guarantee. If you are not satisfied you may return the computer system for a refund.\n",
      "Hello Katherine. We are reviewing your support claim case, and will contact you on your existing ticket shortly.\n",
      "No Reply\n",
      "No Reply\n",
      "No Reply\n",
      "Thank you James, for your 5* response and for being a valued Corsair customer!\n",
      "No Reply\n",
      "No Reply\n"
     ]
    }
   ],
   "source": [
    "def find_reply(txt):\n",
    "    '''\n",
    "    Function to find replies if there are any from a representative\n",
    "    '''\n",
    "    try:\n",
    "        return txt.find_all(\"p\")[3].get_text()\n",
    "    except:\n",
    "        return \"No Reply\"\n",
    "\n",
    "for i in reviews: #Test\n",
    "    print(find_reply(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eaf234",
   "metadata": {},
   "source": [
    "Now find the geography which is just after the word \"review\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3b50dc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB\n",
      "US\n",
      "AT\n",
      "DK\n",
      "GB\n",
      "BA\n",
      "FI\n",
      "UU\n",
      "NO\n",
      "GB\n",
      "US\n",
      "GB\n",
      "BE\n",
      "AJ\n",
      "GB\n",
      "GB\n",
      "GB\n",
      "SJ\n",
      "GB\n",
      "NO\n"
     ]
    }
   ],
   "source": [
    " def find_geo(txt):\n",
    "    '''\n",
    "    Find geography tag for the review\n",
    "    '''\n",
    "    txt = txt.get_text()\n",
    "    start = re.search(\"review\",txt).span()[1] #Not plural because 1 review vs 10 review**s**\n",
    "    return txt[start+1:start+3]\n",
    "\n",
    "for i in reviews: #Test\n",
    "    print(find_geo(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "be825e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Very strange seeing it getting 2star rating any time I've had issues they helped me super quick and always sent me out parts that needed if broken.tje core nodes can be a bit better but in general there are very good.\n"
     ]
    }
   ],
   "source": [
    "def find_body(txt):\n",
    "    '''\n",
    "    Function to find body text\n",
    "    '''\n",
    "#    search = re.finditer(r\"\\d{1}, \\d{4}\",txt)\n",
    "#    end = re.search(\"Date of experience:\",txt).span()[0]\n",
    "#    idxs = [i.span() for i in search]\n",
    "#    #Find the text between the review date and date of experience\n",
    "#    try: #The reviews which are written recently say \"3 hours ago\"\n",
    "#        #find the \"ago\" text\n",
    "#        start = re.search(\" ago\",txt).span()[1]\n",
    "#        return txt[start:end]\n",
    "#    except:\n",
    "#        return txt[idxs[0][1]:end]\n",
    "    title = txt.find_all(\"h2\")[0].get_text()\n",
    "    body = txt.find_all(\"p\")[0].get_text()\n",
    "    return title  + \" \" + body\n",
    "    \n",
    "for i in reviews: #Test\n",
    "    print(find_body(i))\n",
    "    break #dont show all of them in this case ... too much text block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4be933",
   "metadata": {},
   "source": [
    "Now that functions exist for Date, Replies, Region, and Body text.\n",
    "\n",
    "This is only the first page of reviews -- Need to write some code to parse all the pagenation and save the reviews to a .csv file because I don't want to keep polling the webpage if its not necessary!\n",
    "\n",
    "After that, the next steps will be to focus on :\n",
    "- NLP to remove filler words and generate sentiment analysis\n",
    "- Dictionary of all the regions so we can make an analysis based on region!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "8b73dc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "Good Very strange seeing it getting 2star rating any time I've had issues they helped me super quick and always sent me out parts that needed if broken.tje core nodes can be a bit better but in general there are very good.\n"
     ]
    }
   ],
   "source": [
    "def grab_reviews(URL):\n",
    "    dates = [] #Blank\n",
    "    geos = [] #Blank\n",
    "    replies = [] #Blank\n",
    "    reviews = [] #Blank\n",
    "    stars = [] #Blank\n",
    "    for count in range(1,41):\n",
    "        print(count)\n",
    "        if count == 1:\n",
    "            r = requests.get(URL)\n",
    "        else:\n",
    "            r = requests.get(URL+\"?page=\"+str(count))\n",
    "        soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "        review = soup.find_all(\"div\", {\"class\": \"styles_reviewCardInner__EwDq2\"})\n",
    "        star = soup.find_all(\"div\",\"star-rating_starRating__4rrcf star-rating_medium__iN6Ty\")\n",
    "        star = star[1:-3] #Remove first (company overall) and last 3 (other company) stars\n",
    "#        #Debug\n",
    "#        print(len(review))\n",
    "#        print(len(star))\n",
    "        time.sleep(1) #Pause just to not overload the webpage\n",
    "\n",
    "        #Process the data\n",
    "        for i in review:\n",
    "            dates.append(find_date(i))\n",
    "            geos.append(find_geo(i))\n",
    "            reviews.append(find_body(i))\n",
    "            replies.append(find_reply(i))\n",
    "        for j in star:\n",
    "            stars.append(j.find_all(\"img\")[0]['src'][-5])\n",
    "    return [dates,geos,reviews,replies,stars]\n",
    "\n",
    "data = grab_reviews(\"https://www.trustpilot.com/review/www.corsair.com\")\n",
    "print(data[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "022563d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Block to save the data so I don't have to keep polling the webpage\n",
    "import pickle\n",
    "\n",
    "with open('reviews.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "d6adc07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Good Very strange seeing it getting 2star rating any time I've had issues they helped me super quick and always sent me out parts that needed if broken.tje core nodes can be a bit better but in general there are very good.\""
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Block to load the pickled data so we can checkpoint here instead\n",
    "import pickle\n",
    "with open('reviews.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    dat = pickle.load(f)\n",
    "dat[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c91fd9",
   "metadata": {},
   "source": [
    "# NLP Work\n",
    "Now the focus will be to perform some NLP work to\n",
    "- Tokenize words (Ie: Grab individual words)\n",
    "- Normalize Text (Ie: All lowercase letters)\n",
    "- Clean up filler words (Ex: in, on, I)\n",
    "- Do some Sentiment Analysis on each review\n",
    "- Frequency analysis (Ie: What is most commonly said about the company?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "973d68ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'very', 'strange', 'seeing', 'it', 'getting', '2star', 'rating', 'any', 'time', 'i', \"'ve\", 'had', 'issues', 'they']\n"
     ]
    }
   ],
   "source": [
    "[dates,geos,reviews,replies,stars] = dat #Segment the data out into the individual lists\n",
    "txt = reviews[0] #Lets work with the first review\n",
    "\n",
    "print([i.lower() for i in nltk.word_tokenize(txt)][:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be971b6f",
   "metadata": {},
   "source": [
    "Problem: The conjunction word \"I have/had\" became \"i\" and \"'ve\" but should have been \"i've\"\n",
    "\n",
    "Need to utilize a different tokenizer -- Try tweet_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "121e2217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Good', 'Very', 'strange', 'seeing', 'it', 'getting', '2star', 'rating', 'any', 'time', \"I've\", 'had', 'issues', 'they', 'helped']\n",
      "['needed', 'if', 'broken.tje']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "print(tokenizer.tokenize(txt)[:15])\n",
    "print(tokenizer.tokenize(txt)[25:28])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf423d",
   "metadata": {},
   "source": [
    "This works, but there's 2 problems that I would like to fix:\n",
    "- The title of the review (In this case: \"Good\") has no space between it and the start of the review\n",
    "- Human error resulted in \"broken.tje\"\n",
    "> I can't fix the word \"tje\" to \"the\" unless I just manually fix that, but it should hopefully be removed by NLTK through an English Dictionary filter <br>\n",
    "> There is no space after the period, that can be added with a split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "954fda74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'very', 'strange', 'seeing', 'it', 'getting', '2star', 'rating', 'any', 'time', \"i've\", 'had', 'issues', 'they', 'helped', 'me', 'super', 'quick', 'and', 'always', 'sent', 'me', 'out', 'parts', 'that', 'needed', 'if', 'broken', 'tje', 'core', 'nodes', 'can', 'be', 'a', 'bit', 'better', 'but', 'in', 'general', 'there', 'are', 'very', 'good']\n"
     ]
    }
   ],
   "source": [
    "fixed_txt = ' '.join(txt.split('.')) #This will adjust the text to replace periods with spaces\n",
    "txt_token = [i.lower() for i in tokenizer.tokenize(fixed_txt)]\n",
    "print(txt_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "17278444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'strange',\n",
       " 'seeing',\n",
       " 'getting',\n",
       " '2star',\n",
       " 'rating',\n",
       " 'time',\n",
       " \"i've\",\n",
       " 'issues',\n",
       " 'helped',\n",
       " 'super',\n",
       " 'quick',\n",
       " 'always',\n",
       " 'sent',\n",
       " 'parts',\n",
       " 'needed',\n",
       " 'broken',\n",
       " 'tje',\n",
       " 'core',\n",
       " 'nodes',\n",
       " 'bit',\n",
       " 'better',\n",
       " 'general',\n",
       " 'good']"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "removed_stopwords = [i for i in txt_token if i not in stopwords]\n",
    "removed_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af6afb",
   "metadata": {},
   "source": [
    "The word \"Good\" is used multiple times -- We need unique words and how often they appear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "3820f988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'good': 2, 'strange': 1, 'seeing': 1, 'getting': 1, '2star': 1, 'rating': 1, 'time': 1, \"i've\": 1, 'issues': 1, 'helped': 1, ...})"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cln_text = nltk.FreqDist(removed_stopwords)\n",
    "cln_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5a583b",
   "metadata": {},
   "source": [
    "Put all together ... this is a funciton to do all the text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "45489ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 21 samples and 22 outcomes>\n",
      "<FreqDist with 20 samples and 22 outcomes>\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "def clean_text(txt,filter_words=stopwords):\n",
    "    fixed_txt = ' '.join(txt.split('.')) #This will adjust the text to replace periods with spaces\n",
    "    txt_token = [i.lower() for i in tokenizer.tokenize(fixed_txt)]\n",
    "    removed_stopwords = [i for i in txt_token if i not in filter_words]\n",
    "    words_only = [i for i in removed_stopwords if i.isalpha()] #Added to remove [\",\",\"...\"] and [\"1\",\"50\"] entries\n",
    "    dist = nltk.FreqDist(words_only)\n",
    "    return dist\n",
    "\n",
    "tokenized_reviews = []\n",
    "for review in reviews:\n",
    "    tokenized_reviews.append(clean_text(review))\n",
    "print(tokenized_reviews[0])\n",
    "\n",
    "tokenized_replies = []\n",
    "for reply in replies:\n",
    "    if reply != \"No Reply\":\n",
    "        tokenized_replies.append(clean_text(reply))\n",
    "    else:\n",
    "        tokenized_replies.append(\"\")\n",
    "print(tokenized_replies[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "8c23e8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Geo</th>\n",
       "      <th>Review</th>\n",
       "      <th>Reply</th>\n",
       "      <th>Token_Review</th>\n",
       "      <th>Token_Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>January 05, 2021</td>\n",
       "      <td>1</td>\n",
       "      <td>GB</td>\n",
       "      <td>No Reply From corsair no Support Contacted Cor...</td>\n",
       "      <td>Hello Daniel. We're sorry for the delay in res...</td>\n",
       "      <td>{'reply': 2, 'corsair': 3, 'support': 2, 'cont...</td>\n",
       "      <td>{'hello': 1, 'daniel': 1, 'sorry': 1, 'delay':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>November 02, 2022</td>\n",
       "      <td>2</td>\n",
       "      <td>SN</td>\n",
       "      <td>Order Repeat Cancellation I have been attempti...</td>\n",
       "      <td>No Reply</td>\n",
       "      <td>{'order': 4, 'repeat': 1, 'cancellation': 1, '...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>February 22, 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>AU</td>\n",
       "      <td>Probably the best keyboard in the world I have...</td>\n",
       "      <td>Hi Vajira,Thank you so much for the feedback. ...</td>\n",
       "      <td>{'probably': 1, 'best': 2, 'keyboard': 2, 'wor...</td>\n",
       "      <td>{'hi': 1, 'vajira': 1, 'thank': 1, 'much': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>November 08, 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>NU</td>\n",
       "      <td>Just Hate the service corsair provide in India...</td>\n",
       "      <td>No Reply</td>\n",
       "      <td>{'hate': 3, 'service': 9, 'corsair': 8, 'provi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>April 27, 2021</td>\n",
       "      <td>1</td>\n",
       "      <td>SA</td>\n",
       "      <td>I ordered a Corsair VENGEANCE a7200… I ordered...</td>\n",
       "      <td>Thank you for your recent order Euridice. Do y...</td>\n",
       "      <td>{'ordered': 2, 'corsair': 2, 'vengeance': 2, '...</td>\n",
       "      <td>{'thank': 1, 'recent': 1, 'order': 3, 'euridic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date Rating Geo  \\\n",
       "346   January 05, 2021      1  GB   \n",
       "56   November 02, 2022      2  SN   \n",
       "675  February 22, 2019      5  AU   \n",
       "374  November 08, 2020      1  NU   \n",
       "292     April 27, 2021      1  SA   \n",
       "\n",
       "                                                Review  \\\n",
       "346  No Reply From corsair no Support Contacted Cor...   \n",
       "56   Order Repeat Cancellation I have been attempti...   \n",
       "675  Probably the best keyboard in the world I have...   \n",
       "374  Just Hate the service corsair provide in India...   \n",
       "292  I ordered a Corsair VENGEANCE a7200… I ordered...   \n",
       "\n",
       "                                                 Reply  \\\n",
       "346  Hello Daniel. We're sorry for the delay in res...   \n",
       "56                                            No Reply   \n",
       "675  Hi Vajira,Thank you so much for the feedback. ...   \n",
       "374                                           No Reply   \n",
       "292  Thank you for your recent order Euridice. Do y...   \n",
       "\n",
       "                                          Token_Review  \\\n",
       "346  {'reply': 2, 'corsair': 3, 'support': 2, 'cont...   \n",
       "56   {'order': 4, 'repeat': 1, 'cancellation': 1, '...   \n",
       "675  {'probably': 1, 'best': 2, 'keyboard': 2, 'wor...   \n",
       "374  {'hate': 3, 'service': 9, 'corsair': 8, 'provi...   \n",
       "292  {'ordered': 2, 'corsair': 2, 'vengeance': 2, '...   \n",
       "\n",
       "                                           Token_Reply  \n",
       "346  {'hello': 1, 'daniel': 1, 'sorry': 1, 'delay':...  \n",
       "56                                                      \n",
       "675  {'hi': 1, 'vajira': 1, 'thank': 1, 'much': 1, ...  \n",
       "374                                                     \n",
       "292  {'thank': 1, 'recent': 1, 'order': 3, 'euridic...  "
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([dates,stars,geos,reviews,replies,tokenized_reviews,tokenized_replies]).T\n",
    "df.columns = [\"Date\",\"Rating\",\"Geo\",\"Review\",\"Reply\",\"Token_Review\",\"Token_Reply\"]\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d7e95a",
   "metadata": {},
   "source": [
    "Save the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "b000bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(df, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "721c1586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Geo</th>\n",
       "      <th>Review</th>\n",
       "      <th>Reply</th>\n",
       "      <th>Token_Review</th>\n",
       "      <th>Token_Reply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>April 10, 2021</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>Corsair has gotten worse over the years I've g...</td>\n",
       "      <td>Hello Sean. We're sorry to hear about the mous...</td>\n",
       "      <td>{'corsair': 2, 'gotten': 1, 'worse': 1, 'years...</td>\n",
       "      <td>{'hello': 1, 'sean': 1, 'sorry': 1, 'hear': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>July 16, 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>SJ</td>\n",
       "      <td>Mediocre products, the worst customer service....</td>\n",
       "      <td>Hi Hunter,I do apologize for this poor experie...</td>\n",
       "      <td>{'mediocre': 1, 'products': 1, 'worst': 1, 'cu...</td>\n",
       "      <td>{'hi': 1, 'hunter': 1, 'apologize': 1, 'poor':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>July 03, 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>AU</td>\n",
       "      <td>Horrible Shipping It's been exactly 1 week sin...</td>\n",
       "      <td>Hello J. Thank you for your recent order of a ...</td>\n",
       "      <td>{'horrible': 1, 'shipping': 2, 'exactly': 1, '...</td>\n",
       "      <td>{'hello': 1, 'j': 1, 'thank': 1, 'recent': 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>February 20, 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>SU</td>\n",
       "      <td>TICKET #849028 TICKET #849028I bought CMD32GX4...</td>\n",
       "      <td>Hi,Your replacement has been booked, I'll send...</td>\n",
       "      <td>{'ticket': 2, 'bought': 1, 'cmd': 4, 'newegg':...</td>\n",
       "      <td>{'hi': 1, 'replacement': 1, 'booked': 1, 'send...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>November 20, 2021</td>\n",
       "      <td>1</td>\n",
       "      <td>SN</td>\n",
       "      <td>Consider a copy that cares about RMA Today you...</td>\n",
       "      <td>Hello Steve. Corsair has partnered with UPS fo...</td>\n",
       "      <td>{'consider': 2, 'copy': 1, 'cares': 1, 'rma': ...</td>\n",
       "      <td>{'hello': 1, 'steve': 1, 'corsair': 1, 'partne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date Rating Geo  \\\n",
       "300     April 10, 2021      1  US   \n",
       "624      July 16, 2019      1  SJ   \n",
       "439      July 03, 2020      1  AU   \n",
       "677  February 20, 2019      1  SU   \n",
       "221  November 20, 2021      1  SN   \n",
       "\n",
       "                                                Review  \\\n",
       "300  Corsair has gotten worse over the years I've g...   \n",
       "624  Mediocre products, the worst customer service....   \n",
       "439  Horrible Shipping It's been exactly 1 week sin...   \n",
       "677  TICKET #849028 TICKET #849028I bought CMD32GX4...   \n",
       "221  Consider a copy that cares about RMA Today you...   \n",
       "\n",
       "                                                 Reply  \\\n",
       "300  Hello Sean. We're sorry to hear about the mous...   \n",
       "624  Hi Hunter,I do apologize for this poor experie...   \n",
       "439  Hello J. Thank you for your recent order of a ...   \n",
       "677  Hi,Your replacement has been booked, I'll send...   \n",
       "221  Hello Steve. Corsair has partnered with UPS fo...   \n",
       "\n",
       "                                          Token_Review  \\\n",
       "300  {'corsair': 2, 'gotten': 1, 'worse': 1, 'years...   \n",
       "624  {'mediocre': 1, 'products': 1, 'worst': 1, 'cu...   \n",
       "439  {'horrible': 1, 'shipping': 2, 'exactly': 1, '...   \n",
       "677  {'ticket': 2, 'bought': 1, 'cmd': 4, 'newegg':...   \n",
       "221  {'consider': 2, 'copy': 1, 'cares': 1, 'rma': ...   \n",
       "\n",
       "                                           Token_Reply  \n",
       "300  {'hello': 1, 'sean': 1, 'sorry': 1, 'hear': 1,...  \n",
       "624  {'hi': 1, 'hunter': 1, 'apologize': 1, 'poor':...  \n",
       "439  {'hello': 1, 'j': 1, 'thank': 1, 'recent': 1, ...  \n",
       "677  {'hi': 1, 'replacement': 1, 'booked': 1, 'send...  \n",
       "221  {'hello': 1, 'steve': 1, 'corsair': 1, 'partne...  "
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load df\n",
    "import pickle\n",
    "with open('df.pickle', 'rb') as f:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    df = pickle.load(f)\n",
    "df.sample(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
